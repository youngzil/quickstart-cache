1、缓存热点Key、大Value
2、缓存一致性问题
3、Redis和Memcached的区别
4、分布式缓存和Redis Key设计技巧
5、缓存的作用和分类
6、缓存算法（页面置换算法）-FIFO、LFU、LRU
缓存淘汰算法之LRU 
7、
8、








---------------------------------------------------------------------------------------------------------------------
缓存热点Key、大Value 


缓存热点Key：瞬间大量请求，导致缓存集群（Redis、Memcached）存储该热点Key的机器宕机
1、基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如 Storm、Spark Streaming、Flink 或者根据自己的业务还有经验值来自己实现的业务逻辑判定热点数据
2、判定热点数据后，可以把热点数据信息存储到Zookeeper，然后通知所有的应用节点，应用热点缓存自动加载为 JVM 本地缓存（Ehcache、Hashmap等），
3、限流熔断保护，可以作用在后端应用或者缓存集群
总结：应用先从本地缓存-->分布式缓存集群-->数据库，通过zookeeper通知应用加载热点缓存到本地缓存




---------------------------------------------------------------------------------------------------------------------
https://www.cnblogs.com/axtkdd/p/9760786.html
https://www.cnblogs.com/duyinqiang/p/5696253.html
https://blog.csdn.net/justinsause/article/details/51063631



如何保证缓存与数据库的双写一致性？

Cache Aside Pattern
最初级的缓存不一致问题及解决方案
比较复杂的数据不一致问题分析


最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。
读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
更新的时候，先更新数据库，然后再删除缓存。

为什么是删除缓存，而不是更新缓存？
原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。
比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。
其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。


问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
解决思路：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。


先修改数据库，再删除缓存。
    如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
先删除缓存，再修改数据库。
    如果高并发下，还没有修改数据库，又过来一个读请求，又加载老的数据到了缓存中
    不是很及时的数据，可以发到消息队列中，保证消息发送的可靠性，消息中还可以进行删除操作的合并，减少缓存加载的次数


流程如下所示
（1）更新数据库数据；
（2）缓存因为种种问题删除失败
（3）将需要删除的key发送至消息队列
（4）自己消费消息，获得需要删除的key
（5）继续重试删除操作，直到成功




缓存一致性问题：
更新缓存还是淘汰缓存？
更新缓存：先写数据库还是先写缓存？


更新缓存的优点：缓存不会增加一次miss，命中率更高，更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率
淘汰缓存的优点：简单，如果数据操作复杂，淘汰缓存，并且带来的副作用只是增加了一次cache miss



先淘汰缓存再写数据库：
问题：大并发会有缓存击穿 或者 大并发有脏数据
解决：同一份数据库操作串行化（服务、数据库连接根据参数都路由到同一个）

先写数据库再更新缓存：
问题：存在一定时间的不一致性，最终一致性
解决：异步更新，消息总线esb更新等
如果数据库是主从的，主写从读，就要么数据库主从强一致性，或者主写后要等待从写成功如500ms之后再异步更新

强一致性：必然就是全部更新完才能读，导致延迟或者服务不可用



由于数据库层面的读写并发，引发的数据库与缓存数据不一致的问题（本质是后发生的读请求先返回了），可能通过两个小的改动解决：
（1）修改服务Service连接池，id取模选取服务连接，能够保证同一个数据的读写都落在同一个后端服务上
（2）修改数据库DB连接池，id取模选取DB连接，能够保证同一个数据的读写在数据库层面是串行的



1、缓存穿透
    缓存空值
    布隆过滤器拦截
2、缓存击穿
  对特定key设置永不过期
  使用互斥锁(mutex key)
3、缓存雪崩
  缓存时间增加随机值
  Redis节点宕机引起的雪崩
4、缓存与数据库双写一致问题
  更新策略1-先更新数据库，后更新缓存
  更新策略2- 先删除缓存，在更新数据库
  更新策略3-先更新数据库，再删除缓存
5、并发竞争key


并发竞争key：

方法1：用redis事务机制。但不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。

方法2：如果对这个key操作，不要求顺序
这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。

方法3：如果对这个key操作，要求顺序
系统A key 1 {valueA  3:00}
系统B key 1 {valueB  3:05}
系统C key 1 {valueC  3:10}
那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。

方法4：其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。



Redis 缓存穿透、缓存雪崩、缓存击穿、数据库双写一致性、并发竞争key
缓存淘汰、缓存穿透、缓存击穿、缓存雪崩、数据库缓存双写一致性

https://blog.csdn.net/xushiyu1996818/article/details/104175643
https://blog.csdn.net/javaxuexilu/article/details/100738554



---------------------------------------------------------------------------------------------------------------------

Redis和Memcached的区别：
1、持久化
2、数据类型redis多种，memcached比较少
3、负载均衡：memcached是在客户端，redis负载均衡逻辑是在服务端，返回重定向
4、高可用？

redis持久化方式：aof追加操作指令，对文件进行优化和合并、rdb全量备份

Redis和Memcached的区别  
https://blog.csdn.net/u013256816/article/details/51146314  
1、数据结构  
2、数据存储及持久化  
Redis虽然是基于内存的存储系统，但是它本身是支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB快照和AOF日志。而memcached是不支持数据持久化操作的。  
3、内存管理机制不同  
在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，  
4、集群管理和路由、  
Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。  
  
Redis Cluster 集群一致性原理及slot迁移测试  
https://blog.csdn.net/u011535541/article/details/78834565  
移slot如何保证slot归属的一致性.  
从node A迁移一个槽位到node B的流程是:  
(1) node A调用cluster setslot migrating设置migrating flag, node B调用cluster setslot importing设置importing flag  
(2) 调用migrate指令迁移所有该slot的数据到node B  
(3) 对两个节点使用cluster setslot node来消除importing和migrating flag, 并且设置槽位  


---------------------------------------------------------------------------------------------------------------------
缓存的作用和分类

缓存的主要作用是暂时在内存中保存业务系统的数据处理结果，并且等待下次访问使用。
在日长开发有很多场合，有一些数据量不是很大，不会经常改动，并且访问非常频繁。但是由于受限于硬盘IO的性能或者远程网络等原因获取可能非常的费时。会导致我们的程序非常缓慢，这在某些业务上是不能忍的！而缓存正是解决这类问题的神器！


缓存在很多系统和架构中都用广泛的应用,例如：
CPU缓存
操作系统缓存
HTTP缓存
数据库缓存
静态文件缓存
本地缓存
分布式缓存


缓存总体可分为两种 集中式缓存 和 分布式缓存
“集中式缓存"与"分布式缓存"的区别其实就在于“集中”与"非集中"的概念，其对象可能是服务器、内存条、硬盘等。比如：
1.服务器版本：
缓存集中在一台服务器上，为集中式缓存。
缓存分散在不同的服务器上，为分布式缓存。

2.内存条版本：
缓存集中在一台服务器的一条内存条上，为集中式缓存。
缓存分散在一台服务器的不同内存条上，为分布式缓存。

3.硬盘版本：
缓存集中在一台服务器的一个硬盘上，为集中式缓存。
缓存分散在一台服务器的不同硬盘上，为分布式缓存。


---------------------------------------------------------------------------------------------------------------------

分布式缓存和Redis Key设计技巧

参考
/Users/yangzl/git/quickstart-framework/quickstart-document/doc/base/分布式/分布式锁、缓存、主键.md


分布式缓存:

分布式缓存具有如下特性:
1) 高性能
2) 动态扩展性
3) 高可用性
4) 易用性
5) 分布式代码执行(distributed code execution)


参考
https://blog.csdn.net/dinglang_2009/article/details/9071075

---------------------------------------------------------------------------------------------------------------------
   
缓存算法（页面置换算法）-FIFO、LFU、LRU  
当缓存需要被清理时（比如空间占用已经接近临界值了），需要使用某种淘汰算法来决定清理掉哪些数据。常用的淘汰算法有下面几种：  
FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。双向链表：新来的数据放在链表尾部，淘汰时候删除头部  
LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。双向链表/链表/数组+hashmap：一个数组存储数据项，用hashmap存储每个数据项在数组中对应的位置，然后为每个数据项设计一个访问频次  
LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。链表实现  
  
缓存淘汰算法之LRU  
LRU全称是Least Recently Used，即最近最久未使用的意思。  
LRU算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。  
LFU（Least Frequently Used）最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。  
注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。  
https://www.cnblogs.com/dolphin0520/p/3749259.html  
https://www.cnblogs.com/-OYK/archive/2012/12/05/2803317.html  
https://blog.csdn.net/elricboa/article/details/78847305  
https://www.cnblogs.com/lwbqqyumidi/p/3837629.html  

---------------------------------------------------------------------------------------------------------------------



