1、缓存热点Key、大Value
2、缓存一致性问题
3、Redis和Memcached的区别
4、分布式缓存和Redis Key设计技巧
5、缓存的作用和分类
6、缓存算法（页面置换算法）-FIFO、LFU、LRU
缓存淘汰算法之LRU 
7、
8、




redis集群部署的shell脚本
根据配置文件的ip和配置的端口号，集群的节点个数等就可以：
实现单机集群部署
多集集群部署


---------------------------------------------------------------------------------------------------------------------
缓存热点Key、大Value 


缓存热点Key：瞬间大量请求，导致缓存集群（Redis、Memcached）存储该热点Key的机器宕机
1、基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如 Storm、Spark Streaming、Flink 或者根据自己的业务还有经验值来自己实现的业务逻辑判定热点数据
2、判定热点数据后，可以把热点数据信息存储到Zookeeper，然后通知所有的应用节点，应用热点缓存自动加载为 JVM 本地缓存（Ehcache、Hashmap等），
3、限流熔断保护，可以作用在后端应用或者缓存集群
总结：应用先从本地缓存-->分布式缓存集群-->数据库，通过zookeeper通知应用加载热点缓存到本地缓存




---------------------------------------------------------------------------------------------------------------------
https://www.cnblogs.com/axtkdd/p/9760786.html
https://www.cnblogs.com/duyinqiang/p/5696253.html
https://blog.csdn.net/justinsause/article/details/51063631



缓存更新的套路
https://coolshell.cn/articles/17416.html


1、Cache Aside Pattern
2、Read/Write Through Pattern
    Read Through
    Write Through
3、Write Behind Caching Pattern



Read/Write Through Pattern
应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。
读的时候，只读缓存，缓存不存在，就缓存先加载，然后返回
写的时候，缓存存在就写缓存，缓存更新到持久层，缓存不存在直接更新持久层数据库返回



Write Behind 又叫 Write Back。一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法
Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事
Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。
操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。



如何保证缓存与数据库的双写一致性？

Cache Aside Pattern
最初级的缓存不一致问题及解决方案
比较复杂的数据不一致问题分析

Cache Aside Pattern(缓存模式)解析

对于读请求
    先读cache，再读db
    如果，cache hit，则直接返回数据
    如果，cache miss，则访问db，并将数据set回缓存

对于写请求
    淘汰缓存，而不是更新缓存
    先操作数据库，再淘汰缓存,第一步要操作数据库，第二步操作缓存，采用delete淘汰，而不是set更新

Cache Aside Pattern为什么建议淘汰缓存，而不是更新缓存?
答：如果更新缓存，在并发写时，可能出现数据不一致。

如果采用set缓存。在1和2两个并发写发生时，由于无法保证时序，此时不管先操作缓存还是先操作数据库，都可能出现：
    请求1先操作数据库，请求2后操作数据库
    请求2先set了缓存，请求1后set了缓存
    导致，数据库与缓存之间的数据不一致。
所以，Cache Aside Pattern建议，delete缓存，而不是set缓存。

Cache Aside Pattern为什么建议先操作数据库，再操作缓存?
答：如果先操作缓存，在读写并发时，可能出现数据不一致。

如果先操作缓存。在1和2并发读写发生时，由于无法保证时序，可能出现：
    写请求淘汰了缓存
    写请求操作了数据库(主从同步没有完成)
    读请求读了缓存(cache miss)
    读请求读了从库(读了一个旧数据)
    读请求set回缓存(set了一个旧数据)
    数据库主从同步完成
    导致，数据库与缓存的数据不一致。
所以，Cache Aside Pattern建议，先操作数据库，再操作缓存。

Cache Aside Pattern方案存在什么问题?
答：如果先操作数据库，再淘汰缓存，在原子性被破坏时：

修改数据库成功了
淘汰缓存失败了
导致，数据库与缓存的数据不一致。






最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。
读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
更新的时候，先更新数据库，然后再删除缓存。

为什么是删除缓存，而不是更新缓存？
原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。
比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。
其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。


问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
解决思路：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。


先修改数据库，再删除缓存。
    如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
先删除缓存，再修改数据库。
    如果高并发下，还没有修改数据库，又过来一个读请求，又加载老的数据到了缓存中
    不是很及时的数据，可以发到消息队列中，保证消息发送的可靠性，消息中还可以进行删除操作的合并，减少缓存加载的次数


流程如下所示
（1）更新数据库数据；
（2）缓存因为种种问题删除失败
（3）将需要删除的key发送至消息队列
（4）自己消费消息，获得需要删除的key
（5）继续重试删除操作，直到成功



几种更新缓存方法
1. 更新数据库，同步更新缓存。缓存失败，异步继续更新。保证重试成功

2. 更是数据库，同步失效缓存。失效缓存失败，异步失效缓存。保证重试成功

3. 读取缓存，缓存失效，读取数据库，并同步更新缓存。更新失败不重试。

 

使用场景
1. 读多写少
更新数据库较少，可以在更新数据库的同时更新缓存，尽量保证数据库和缓存的同步性。

由于有数据失效时间，所以读取的时间如果数据失效，需要读取数据库后更新缓存

如果并发特别高，需要防止缓存失效产生穿透问题，造成数据库读取瞬时压力居高。可以使用锁机制。

 

2. 写多读少
如果写入并发量较高，读取量比较低，可以直接在写入时候失效缓存，读取时候读取数据库并更新缓存

由于读取较少，如果写入量不大，可以在写入数据库时同步更新缓存。

 

3. 读多写多

写入并发高，并且读取并发高，如果写入数据量较大，可以存在主从同步造成主库网卡打满的问题。所以写入数据库时候可以失效缓存。

读取缓存失效，同步读取数据库，并更新缓存。如果对接口相应要求高，可以异步更新缓存，需要控制异步线程数量。
————————————————
版权声明：本文为CSDN博主「fatshaw」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/fatshaw/article/details/52815404












缓存一致性问题：
更新缓存还是淘汰缓存？
更新缓存：先写数据库还是先写缓存？


更新缓存的优点：缓存不会增加一次miss，命中率更高，更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率
淘汰缓存的优点：简单，如果数据操作复杂，淘汰缓存，并且带来的副作用只是增加了一次cache miss



先淘汰缓存再写数据库：
问题：大并发会有缓存击穿 或者 大并发有脏数据
解决：同一份数据库操作串行化（服务、数据库连接根据参数都路由到同一个）

先写数据库再更新缓存：
问题：存在一定时间的不一致性，最终一致性
解决：异步更新，消息总线esb更新等
如果数据库是主从的，主写从读，就要么数据库主从强一致性，或者主写后要等待从写成功如500ms之后再异步更新

强一致性：必然就是全部更新完才能读，导致延迟或者服务不可用



由于数据库层面的读写并发，引发的数据库与缓存数据不一致的问题（本质是后发生的读请求先返回了），可能通过两个小的改动解决：
（1）修改服务Service连接池，id取模选取服务连接，能够保证同一个数据的读写都落在同一个后端服务上
（2）修改数据库DB连接池，id取模选取DB连接，能够保证同一个数据的读写在数据库层面是串行的



1、缓存穿透
    缓存空值
    布隆过滤器拦截
2、缓存击穿
  对特定key设置永不过期
  使用互斥锁(mutex key)
3、缓存雪崩
  缓存时间增加随机值
  Redis节点宕机引起的雪崩
4、缓存与数据库双写一致问题
  更新策略1-先更新数据库，后更新缓存
  更新策略2- 先删除缓存，在更新数据库
  更新策略3-先更新数据库，再删除缓存
5、并发竞争key


并发竞争key：

方法1：用redis事务机制。但不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。

方法2：如果对这个key操作，不要求顺序
这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。

方法3：如果对这个key操作，要求顺序
系统A key 1 {valueA  3:00}
系统B key 1 {valueB  3:05}
系统C key 1 {valueC  3:10}
那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。

方法4：其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。



Redis 缓存穿透、缓存雪崩、缓存击穿、数据库缓存双写一致性、并发竞争key
缓存淘汰



https://blog.csdn.net/xushiyu1996818/article/details/104175643
https://blog.csdn.net/javaxuexilu/article/details/100738554



---------------------------------------------------------------------------------------------------------------------

Redis和Memcached的区别：
1、持久化
2、数据类型redis多种，memcached比较少
3、负载均衡：memcached是在客户端，redis负载均衡逻辑是在服务端，返回重定向
4、高可用？

redis持久化方式：aof追加操作指令，对文件进行优化和合并、rdb全量备份

Redis和Memcached的区别  
https://blog.csdn.net/u013256816/article/details/51146314  
1、数据结构  
2、数据存储及持久化  
Redis虽然是基于内存的存储系统，但是它本身是支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB快照和AOF日志。而memcached是不支持数据持久化操作的。  
3、内存管理机制不同  
在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，  
4、集群管理和路由、  
Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。  
  
Redis Cluster 集群一致性原理及slot迁移测试  
https://blog.csdn.net/u011535541/article/details/78834565  
移slot如何保证slot归属的一致性.  
从node A迁移一个槽位到node B的流程是:  
(1) node A调用cluster setslot migrating设置migrating flag, node B调用cluster setslot importing设置importing flag  
(2) 调用migrate指令迁移所有该slot的数据到node B  
(3) 对两个节点使用cluster setslot node来消除importing和migrating flag, 并且设置槽位  


---------------------------------------------------------------------------------------------------------------------
缓存的作用和分类

缓存的主要作用是暂时在内存中保存业务系统的数据处理结果，并且等待下次访问使用。
在日长开发有很多场合，有一些数据量不是很大，不会经常改动，并且访问非常频繁。但是由于受限于硬盘IO的性能或者远程网络等原因获取可能非常的费时。会导致我们的程序非常缓慢，这在某些业务上是不能忍的！而缓存正是解决这类问题的神器！


缓存在很多系统和架构中都用广泛的应用,例如：
CPU缓存
操作系统缓存
HTTP缓存
数据库缓存
静态文件缓存
本地缓存
分布式缓存


缓存总体可分为两种 集中式缓存 和 分布式缓存
“集中式缓存"与"分布式缓存"的区别其实就在于“集中”与"非集中"的概念，其对象可能是服务器、内存条、硬盘等。比如：
1.服务器版本：
缓存集中在一台服务器上，为集中式缓存。
缓存分散在不同的服务器上，为分布式缓存。

2.内存条版本：
缓存集中在一台服务器的一条内存条上，为集中式缓存。
缓存分散在一台服务器的不同内存条上，为分布式缓存。

3.硬盘版本：
缓存集中在一台服务器的一个硬盘上，为集中式缓存。
缓存分散在一台服务器的不同硬盘上，为分布式缓存。


---------------------------------------------------------------------------------------------------------------------

分布式缓存和Redis Key设计技巧

参考
/Users/yangzl/git/quickstart-framework/quickstart-document/doc/base/分布式/分布式锁、缓存、主键.md


分布式缓存:

分布式缓存具有如下特性:
1) 高性能
2) 动态扩展性
3) 高可用性
4) 易用性
5) 分布式代码执行(distributed code execution)


参考
https://blog.csdn.net/dinglang_2009/article/details/9071075

---------------------------------------------------------------------------------------------------------------------
   
缓存算法（页面置换算法）-FIFO、LFU、LRU  
当缓存需要被清理时（比如空间占用已经接近临界值了），需要使用某种淘汰算法来决定清理掉哪些数据。常用的淘汰算法有下面几种：  
FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。双向链表：新来的数据放在链表尾部，淘汰时候删除头部  
LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。双向链表/链表/数组+hashmap：一个数组存储数据项，用hashmap存储每个数据项在数组中对应的位置，然后为每个数据项设计一个访问频次  
LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。链表实现  
  
缓存淘汰算法之LRU  
LRU全称是Least Recently Used，即最近最久未使用的意思。  
LRU算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。  
LFU（Least Frequently Used）最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。  
注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。 

LFU缺点：短时间大量访问的热点数据不会被淘汰
 
https://www.cnblogs.com/dolphin0520/p/3749259.html  
https://www.cnblogs.com/-OYK/archive/2012/12/05/2803317.html  
https://blog.csdn.net/elricboa/article/details/78847305  
https://www.cnblogs.com/lwbqqyumidi/p/3837629.html  

---------------------------------------------------------------------------------------------------------------------



